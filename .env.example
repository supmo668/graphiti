# ========================================
# LLM Provider API Keys (choose one or more)
# ========================================
OPENAI_API_KEY=                          # OpenAI GPT models (gpt-4, gpt-3.5-turbo)
ANTHROPIC_API_KEY=                       # Anthropic Claude models
GOOGLE_API_KEY=                          # Google Gemini models
GROQ_API_KEY=                            # Groq inference API

# ========================================
# Embedding Provider API Keys (choose one)
# ========================================
# OPENAI_API_KEY=                        # OpenAI embeddings (text-embedding-ada-002, text-embedding-3-*)
VOYAGE_API_KEY=                          # Voyage AI embeddings
# GOOGLE_API_KEY=                        # Gemini embeddings

# ========================================
# Graph Database Configuration (choose one)
# ========================================

# Neo4j (recommended for local development)
NEO4J_URI=bolt://localhost:7687
NEO4J_PORT=7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# FalkorDB (Redis-based graph database)
FALKORDB_URI=
FALKORDB_PORT=
FALKORDB_USER=
FALKORDB_PASSWORD=

# AWS Neptune (managed graph database)
NEPTUNE_ENDPOINT=
NEPTUNE_PORT=8182
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# Milvus (vector database)
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_USER=
MILVUS_PASSWORD=

# ========================================
# Search Backend Configuration (optional)
# ========================================
# AWS OpenSearch (for hybrid search with Neo4j)
OPENSEARCH_ENDPOINT=
OPENSEARCH_PORT=443
OPENSEARCH_COLLECTION_NAME=
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# ========================================
# Server Configuration
# ========================================
PORT=8000
HOST=0.0.0.0

# ========================================
# Performance & Runtime Settings
# ========================================
USE_PARALLEL_RUNTIME=true                # Enable concurrent processing
SEMAPHORE_LIMIT=10                       # Max concurrent LLM requests
MAX_REFLEXION_ITERATIONS=3               # Max extraction refinement iterations

# ========================================
# Observability & Tracing (optional)
# ========================================
ENABLE_TRACING=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
OTEL_SERVICE_NAME=graphiti
OTEL_RESOURCE_ATTRIBUTES=

# ========================================
# Development & Testing
# ========================================
GITHUB_SHA=                              # For CI/CD tracking
LOG_LEVEL=INFO                           # DEBUG, INFO, WARNING, ERROR
DISABLE_TELEMETRY=false                  # Opt-out of anonymous usage stats